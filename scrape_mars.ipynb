{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dendencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import pymongo\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dendencies not sure if this one is needed\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Browser\n",
    "def init_browser():\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    return browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create browser function to call as needed with scraping\n",
    "#def init_browser():\n",
    "#    from webdriver_manager.chrome import ChromeDriverManager\n",
    "#    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "   \n",
    "#    return Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(exectabel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scraping function\n",
    "def scrape():\n",
    "    mars_dict = {}\n",
    "    browser = init_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url that is being scraped\n",
    "url = 'https://mars.nasa.gov/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "html = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with ‘html.parser’\n",
    "soup = bs(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"content_title\">\n",
      "<a href=\"/news/8936/nasas-ingenuity-helicopter-to-begin-new-demonstration-phase/\">\n",
      "NASA's Ingenuity Helicopter to Begin New Demonstration Phase\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8919/nasa-to-attempt-first-controlled-flight-on-mars-as-soon-as-monday/\">\n",
      "NASA to Attempt First Controlled Flight on Mars As Soon As Monday\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8896/nasa-ingenuity-mars-helicopter-prepares-for-first-flight/\">\n",
      "NASA Ingenuity Mars Helicopter Prepares for First Flight\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8882/nasas-perseverance-drives-on-mars-terrain-for-first-time/\">\n",
      "NASA's Perseverance Drives on Mars' Terrain for First Time\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8880/nasa-awards-mars-ascent-propulsion-system-contract-for-sample-return/\">\n",
      "NASA Awards Mars Ascent Propulsion System Contract for Sample Return\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8878/nasa-to-provide-update-on-perseverance-firsts-since-mars-landing/\">\n",
      "NASA to Provide Update on Perseverance ‘Firsts' Since Mars Landing \n",
      "</a>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# Store first head line from news_title\n",
    "news_title = soup.find_all('div', class_='content_title')\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url that is being scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "#browser = init_browser()\n",
    "#browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-93538450654b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Scrape NASA website for News for paragraph and assign text to a variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnews_para\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"article_teaser_body\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "# Scrape NASA website for News for paragraph and assign text to a variable\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "news_para = soup.find_all('div', class_=\"article_teaser_body\")\n",
    "news_Title = news_title[0].text\n",
    "news_p = news_para[0].text\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
